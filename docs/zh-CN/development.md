# å¼€å‘æŒ‡å—

## ç›®å½•

- [å¼€å‘ç¯å¢ƒæ­å»º](#å¼€å‘ç¯å¢ƒæ­å»º)
- [é¡¹ç›®æ¶æ„è¯¦è§£](#é¡¹ç›®æ¶æ„è¯¦è§£)
- [ä»£ç é£æ ¼ä¸è§„èŒƒ](#ä»£ç é£æ ¼ä¸è§„èŒƒ)
- [æ·»åŠ æ–°åŠŸèƒ½](#æ·»åŠ æ–°åŠŸèƒ½)
- [æµ‹è¯•æŒ‡å—](#æµ‹è¯•æŒ‡å—)
- [è°ƒè¯•æŠ€å·§](#è°ƒè¯•æŠ€å·§)
- [æ€§èƒ½åˆ†æ](#æ€§èƒ½åˆ†æ)
- [è´¡çŒ®æµç¨‹](#è´¡çŒ®æµç¨‹)
- [å‘å¸ƒæµç¨‹](#å‘å¸ƒæµç¨‹)

## å¼€å‘ç¯å¢ƒæ­å»º

### å…ˆå†³æ¡ä»¶

- Python 3.10 æˆ–æ›´é«˜ç‰ˆæœ¬
- Git ç‰ˆæœ¬æ§åˆ¶å·¥å…·
- è™šæ‹Ÿç¯å¢ƒå·¥å…·ï¼ˆvenvã€conda æˆ– virtualenvï¼‰
- æ”¯æŒ Python çš„ IDEï¼ˆæ¨è VSCodeã€PyCharmï¼‰

### åˆå§‹è®¾ç½®

1. **Fork å¹¶å…‹éš†ä»“åº“**
```bash
# é¦–å…ˆåœ¨ GitHub ä¸Š Fork ä»“åº“
git clone https://github.com/YOUR_USERNAME/ryze-data.git
cd ryze-data
git remote add upstream https://github.com/original/ryze-data.git
```

2. **åˆ›å»ºå¼€å‘ç¯å¢ƒ**
```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv-dev
source venv-dev/bin/activate  # Windows ç³»ç»Ÿ: venv-dev\Scripts\activate

# å®‰è£…å¼€å‘ä¾èµ–
pip install -r requirements.txt
pip install -r requirements-dev.txt
```

3. **é…ç½®é¢„æäº¤é’©å­**
```bash
# å®‰è£… pre-commit
pip install pre-commit

# è®¾ç½®é’©å­
pre-commit install

# æ‰‹åŠ¨è¿è¡Œé’©å­
pre-commit run --all-files
```

4. **IDE é…ç½®**

**VSCode é…ç½®æ–‡ä»¶ settings.json:**
```json
{
    "python.linting.enabled": true,
    "python.linting.pylintEnabled": true,
    "python.linting.flake8Enabled": true,
    "python.formatting.provider": "black",
    "python.testing.pytestArgs": ["tests"],
    "python.testing.unittestEnabled": false,
    "python.testing.pytestEnabled": true,
    "editor.formatOnSave": true
}
```

**PyCharm é…ç½®ï¼š**
- è®¾ç½® Python è§£é‡Šå™¨ä¸ºè™šæ‹Ÿç¯å¢ƒ
- å¯ç”¨ä»£ç æ£€æŸ¥
- é…ç½® pytest ä½œä¸ºæµ‹è¯•è¿è¡Œå™¨
- è®¾ç½® Black ä½œä¸ºä»£ç æ ¼å¼åŒ–å·¥å…·

## é¡¹ç›®æ¶æ„è¯¦è§£

### ç›®å½•ç»“æ„è¯´æ˜

```
src/
â”œâ”€â”€ cli/                     # å‘½ä»¤è¡Œæ¥å£
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py             # âœ… CLI å…¥å£ç‚¹
â”‚   â””â”€â”€ data_inspector.py   # âœ… æ•°æ®æ£€æŸ¥å·¥å…·
â”œâ”€â”€ scrapers/               # ç½‘é¡µçˆ¬è™«æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_scraper.py     # æŠ½è±¡åŸºç±»
â”‚   â””â”€â”€ nature_scraper.py   # âœ… Nature å®ç°
â”œâ”€â”€ config_manager.py       # âœ… é…ç½®ç®¡ç†
â”œâ”€â”€ pipeline_manager.py     # âš ï¸ æµæ°´çº¿æ¡†æ¶ï¼ˆéƒ¨åˆ†å®ç°ï¼‰
â”œâ”€â”€ api_key_balancer.py     # âœ… API å¯†é’¥è´Ÿè½½å‡è¡¡
â””â”€â”€ chunked-ocr.py          # âœ… åˆ†å— OCR å¤„ç†
```

**å®ç°çŠ¶æ€è¯´æ˜**ï¼š
- âœ… å·²å®Œå…¨å®ç°
- âš ï¸ æ¡†æ¶å·²å®ç°ï¼ŒåŠŸèƒ½éƒ¨åˆ†å®Œæˆ
- ğŸ“‹ è®¡åˆ’ä¸­çš„æ¨¡å—ï¼ˆdownloaders/, processors/, generators/ï¼‰å°šæœªå®ç°

### è®¾è®¡æ¨¡å¼

#### 1. **æŠ½è±¡å·¥å‚æ¨¡å¼**

ç”¨äºåˆ›å»ºä¸åŒç±»å‹çš„å¤„ç†å™¨å’Œç”Ÿæˆå™¨ï¼š

```python
from abc import ABC, abstractmethod

class BaseProcessor(ABC):
    """æ‰€æœ‰å¤„ç†å™¨çš„æŠ½è±¡åŸºç±»"""
    
    @abstractmethod
    def process(self, input_data):
        """å¤„ç†è¾“å…¥æ•°æ®"""
        pass
    
    @abstractmethod
    def validate_input(self, input_data):
        """å¤„ç†å‰éªŒè¯è¾“å…¥"""
        pass
    
    @abstractmethod
    def validate_output(self, output_data):
        """å¤„ç†åéªŒè¯è¾“å‡º"""
        pass

class OCRProcessor(BaseProcessor):
    """OCR å¤„ç†çš„å…·ä½“å®ç°"""
    
    def process(self, input_data):
        # å®ç°ç»†èŠ‚
        pass
```

#### 2. **å•ä¾‹æ¨¡å¼**

ç”¨äºé…ç½®ç®¡ç†ï¼š

```python
class ConfigManager:
    _instance = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(ConfigManager, cls).__new__(cls)
        return cls._instance
```

#### 3. **ç­–ç•¥æ¨¡å¼**

ç”¨äºä¸åŒçš„é—®ç­”ç”Ÿæˆç­–ç•¥ï¼š

```python
class QAGenerationStrategy(ABC):
    @abstractmethod
    def generate(self, context, config):
        pass

class FactualQAStrategy(QAGenerationStrategy):
    def generate(self, context, config):
        # ç”Ÿæˆäº‹å®å‹é—®ç­”å¯¹
        pass

class ConceptualQAStrategy(QAGenerationStrategy):
    def generate(self, context, config):
        # ç”Ÿæˆæ¦‚å¿µå‹é—®ç­”å¯¹
        pass
```

## ä»£ç é£æ ¼ä¸è§„èŒƒ

### Python ä»£ç è§„èŒƒ

æˆ‘ä»¬éµå¾ª PEP 8 è§„èŒƒï¼Œå¹¶æœ‰ä»¥ä¸‹è¡¥å……è§„å®šï¼š

1. **è¡Œé•¿åº¦**ï¼šæœ€å¤§ 88 å­—ç¬¦ï¼ˆBlack é»˜è®¤å€¼ï¼‰
2. **å¯¼å…¥é¡ºåº**ï¼š
   ```python
   # æ ‡å‡†åº“
   import os
   import sys
   
   # ç¬¬ä¸‰æ–¹åº“
   import numpy as np
   import pandas as pd
   
   # æœ¬åœ°å¯¼å…¥
   from src.config_manager import ConfigManager
   from src.utils import logger
   ```

3. **æ–‡æ¡£å­—ç¬¦ä¸²**ï¼šä½¿ç”¨ Google é£æ ¼
   ```python
   def process_data(input_file: str, output_dir: str, batch_size: int = 10) -> dict:
       """å¤„ç†è¾“å…¥æ–‡ä»¶ä¸­çš„æ•°æ®å¹¶ä¿å­˜åˆ°è¾“å‡ºç›®å½•ã€‚
       
       Args:
           input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
           output_dir: è¾“å‡ºæ–‡ä»¶ç›®å½•
           batch_size: æ‰¹å¤„ç†å¤§å°
       
       Returns:
           åŒ…å«å¤„ç†ç»“æœçš„å­—å…¸
       
       Raises:
           FileNotFoundError: è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨æ—¶
           ValueError: batch_size å°äº 1 æ—¶
       """
       pass
   ```

4. **ç±»å‹æ³¨è§£**ï¼šæ‰€æœ‰å…¬å…±å‡½æ•°å¿…é¡»ä½¿ç”¨
   ```python
   from typing import List, Dict, Optional, Union
   
   def parse_config(config_path: str) -> Dict[str, Any]:
       pass
   ```

### ä»£ç è´¨é‡å·¥å…·

```bash
# æ ¼å¼åŒ–ä»£ç 
black src/ tests/

# æ£€æŸ¥ä»£ç é£æ ¼
flake8 src/ tests/

# é™æ€ç±»å‹æ£€æŸ¥
mypy src/

# å®‰å…¨æ€§æ£€æŸ¥
bandit -r src/

# å¤æ‚åº¦åˆ†æ
radon cc src/ -s
```

## æ·»åŠ æ–°åŠŸèƒ½

### 1. æ·»åŠ æ–°çš„çˆ¬è™«

é€šè¿‡æ‰©å±• `BaseScraper` åˆ›å»ºæ–°çˆ¬è™«ï¼š

```python
# src/scrapers/arxiv_scraper.py
from typing import List, Dict, Any
from src.scrapers.base_scraper import BaseScraper

class ArxivScraper(BaseScraper):
    """arXiv è®ºæ–‡çˆ¬è™«"""
    
    def __init__(self, output_dir: str, config: dict = None):
        super().__init__(output_dir, config)
        self.base_url = "https://arxiv.org"
    
    def scrape(self, query: str = None) -> List[Dict[str, Any]]:
        """æ ¹æ®æŸ¥è¯¢æ¡ä»¶çˆ¬å– arXiv è®ºæ–‡"""
        # å®ç°ç»†èŠ‚
        pass
    
    def parse_paper(self, paper_html: str) -> Dict[str, Any]:
        """è§£æå•ç¯‡è®ºæ–‡çš„å…ƒæ•°æ®"""
        # å®ç°ç»†èŠ‚
        pass
```

åœ¨æµæ°´çº¿ä¸­æ³¨å†Œçˆ¬è™«ï¼š

```python
# src/pipeline_manager.py
from src.scrapers.arxiv_scraper import ArxivScraper

# åœ¨ PipelineManager.__init__ ä¸­
self.scrapers['arxiv'] = ArxivScraper
```

### 2. æ·»åŠ æ–°çš„å¤„ç†å™¨

```python
# src/processors/table_extractor.py
from src.processors.base_processor import BaseProcessor

class TableExtractor(BaseProcessor):
    """ä»æ–‡æ¡£ä¸­æå–è¡¨æ ¼"""
    
    def process(self, input_data):
        """æå–è¾“å…¥æ•°æ®ä¸­çš„è¡¨æ ¼"""
        tables = []
        # æå–é€»è¾‘
        return tables
    
    def validate_input(self, input_data):
        """ç¡®ä¿è¾“å…¥æ˜¯æœ‰æ•ˆçš„æ–‡æ¡£æ•°æ®"""
        # éªŒè¯é€»è¾‘
        return True
    
    def validate_output(self, output_data):
        """ç¡®ä¿æå–çš„è¡¨æ ¼æœ‰æ•ˆ"""
        # éªŒè¯é€»è¾‘
        return True
```

### 3. æ·»åŠ æ–°çš„ CLI å‘½ä»¤

```python
# src/cli/main.py
@cli.command()
@click.option('--format', type=click.Choice(['json', 'csv']), default='json')
@click.pass_context
def export(ctx, format):
    """ä»¥æŒ‡å®šæ ¼å¼å¯¼å‡ºå¤„ç†åçš„æ•°æ®"""
    cfg = ctx.obj['config']
    
    if format == 'json':
        export_json(cfg)
    elif format == 'csv':
        export_csv(cfg)
    
    click.echo(f"å·²å®Œæˆ {format} æ ¼å¼å¯¼å‡º")
```

## æµ‹è¯•æŒ‡å—

### æµ‹è¯•ç»“æ„

```
tests/
â”œâ”€â”€ unit/                    # å•å…ƒæµ‹è¯•
â”‚   â”œâ”€â”€ test_config_manager.py
â”‚   â”œâ”€â”€ test_scrapers.py
â”‚   â””â”€â”€ test_processors.py
â”œâ”€â”€ integration/             # é›†æˆæµ‹è¯•
â”‚   â”œâ”€â”€ test_pipeline.py
â”‚   â””â”€â”€ test_end_to_end.py
â”œâ”€â”€ fixtures/                # æµ‹è¯•å›ºä»¶
â”‚   â”œâ”€â”€ sample_data.py
â”‚   â””â”€â”€ mock_responses.py
â””â”€â”€ conftest.py             # Pytest é…ç½®
```

### ç¼–å†™æµ‹è¯•

#### å•å…ƒæµ‹è¯•ç¤ºä¾‹

```python
# tests/unit/test_processors.py
import pytest
from unittest.mock import Mock, patch
from src.processors.ocr_processor import OCRProcessor

class TestOCRProcessor:
    """OCR å¤„ç†å™¨æµ‹è¯•å¥—ä»¶"""
    
    @pytest.fixture
    def processor(self):
        """åˆ›å»ºå¤„ç†å™¨å®ä¾‹"""
        return OCRProcessor(config={'batch_size': 10})
    
    def test_process_valid_pdf(self, processor, tmp_path):
        """æµ‹è¯•å¤„ç†æœ‰æ•ˆ PDF æ–‡ä»¶"""
        # å‡†å¤‡
        pdf_file = tmp_path / "test.pdf"
        pdf_file.write_bytes(b"PDF content")
        
        # æ‰§è¡Œ
        result = processor.process(str(pdf_file))
        
        # æ–­è¨€
        assert result is not None
        assert 'text' in result
        assert 'images' in result
    
    def test_process_invalid_file(self, processor):
        """æµ‹è¯•å¤„ç†æ— æ•ˆæ–‡ä»¶"""
        with pytest.raises(FileNotFoundError):
            processor.process("nonexistent.pdf")
    
    @patch('src.processors.ocr_processor.marker')
    def test_ocr_error_handling(self, mock_marker, processor):
        """æµ‹è¯• OCR é”™è¯¯å¤„ç†"""
        mock_marker.convert.side_effect = Exception("OCR å¤±è´¥")
        
        with pytest.raises(ProcessingError):
            processor.process("test.pdf")
```

#### é›†æˆæµ‹è¯•ç¤ºä¾‹

```python
# tests/integration/test_pipeline.py
import pytest
from src.pipeline_manager import PipelineManager
from src.config_manager import ConfigManager

@pytest.mark.integration
class TestPipeline:
    """æµæ°´çº¿é›†æˆæµ‹è¯•"""
    
    def test_full_pipeline(self, sample_data):
        """æµ‹è¯•å®Œæ•´æµæ°´çº¿æ‰§è¡Œ"""
        # è®¾ç½®
        config = ConfigManager()
        config.load("tests/config.test.json")
        pipeline = PipelineManager(config)
        
        # è¿è¡Œæµæ°´çº¿ï¼ˆå½“å‰å·²å®ç°çš„é˜¶æ®µï¼šscrape, ocrï¼‰
        result = pipeline.run(stages=['scrape', 'ocr'])

        # éªŒè¯
        assert result.completed_stages == 2
        assert result.failed_stages == 0
```

### è¿è¡Œæµ‹è¯•

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest

# ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
pytest --cov=src --cov-report=html

# è¿è¡Œç‰¹å®šæµ‹è¯•æ–‡ä»¶
pytest tests/unit/test_config_manager.py

# è¿è¡ŒåŒ¹é…æ¨¡å¼çš„æµ‹è¯•
pytest -k "test_ocr"

# è¯¦ç»†è¾“å‡º
pytest -v

# ä»…è¿è¡Œé›†æˆæµ‹è¯•
pytest -m integration

# å¹¶è¡Œæ‰§è¡Œæµ‹è¯•
pytest -n auto
```

## è°ƒè¯•æŠ€å·§

### 1. ä½¿ç”¨ Python è°ƒè¯•å™¨

```python
# åœ¨ä»£ç ä¸­æ·»åŠ æ–­ç‚¹
import pdb; pdb.set_trace()

# æˆ–ä½¿ç”¨ Python 3.7+ çš„å†…ç½®æ–­ç‚¹
breakpoint()

# IPython è°ƒè¯•å™¨ï¼ˆæ›´å¥½çš„ç•Œé¢ï¼‰
import ipdb; ipdb.set_trace()
```

### 2. è°ƒè¯•æ—¥å¿—

```python
import logging

# é…ç½®è°ƒè¯•æ—¥å¿—
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)

def process_data(data):
    logger.debug(f"å¤„ç†æ•°æ®: {data[:100]}...")  # è®°å½•å‰ 100 ä¸ªå­—ç¬¦
    
    try:
        result = transform(data)
        logger.debug(f"è½¬æ¢æˆåŠŸ: {len(result)} é¡¹")
    except Exception as e:
        logger.error(f"è½¬æ¢å¤±è´¥: {e}", exc_info=True)
        raise
    
    return result
```

### 3. VSCode è¿œç¨‹è°ƒè¯•

```json
// .vscode/launch.json
{
    "version": "0.2.0",
    "configurations": [
        {
            "name": "è°ƒè¯•æµæ°´çº¿",
            "type": "python",
            "request": "launch",
            "module": "src.cli.main",
            "args": ["pipeline", "--stages", "ocr"],
            "console": "integratedTerminal",
            "justMyCode": false
        }
    ]
}
```

## æ€§èƒ½åˆ†æ

### 1. CPU æ€§èƒ½åˆ†æ

```python
import cProfile
import pstats
from pstats import SortKey

# åˆ†æä»£ç å—
profiler = cProfile.Profile()
profiler.enable()

# ä½ çš„ä»£ç 
process_large_dataset()

profiler.disable()

# æ‰“å°ç»Ÿè®¡ä¿¡æ¯
stats = pstats.Stats(profiler)
stats.sort_stats(SortKey.CUMULATIVE)
stats.print_stats(10)  # å‰ 10 ä¸ªå‡½æ•°

# ä¿å­˜åˆ†ææ•°æ®
stats.dump_stats('profile_data.prof')
```

### 2. å†…å­˜åˆ†æ

```python
from memory_profiler import profile

@profile
def memory_intensive_function():
    # ä½¿ç”¨å¤§é‡å†…å­˜çš„å‡½æ•°
    large_list = [i for i in range(1000000)]
    return large_list

# è¿è¡Œ: python -m memory_profiler script.py
```

### 3. è¡Œçº§åˆ†æ

```python
# å®‰è£…: pip install line_profiler

from line_profiler import LineProfiler

def slow_function():
    result = []
    for i in range(1000):
        result.append(i ** 2)
    return result

lp = LineProfiler()
lp_wrapper = lp(slow_function)
lp_wrapper()
lp.print_stats()
```

## è´¡çŒ®æµç¨‹

### 1. åˆ†æ”¯ç­–ç•¥

```bash
# åˆ›å»ºåŠŸèƒ½åˆ†æ”¯
git checkout -b feature/new-scraper

# åˆ›å»ºä¿®å¤åˆ†æ”¯
git checkout -b bugfix/ocr-timeout

# åˆ›å»ºç´§æ€¥ä¿®å¤åˆ†æ”¯
git checkout -b hotfix/critical-issue
```

### 2. æäº¤è§„èŒƒ

éµå¾ªçº¦å®šå¼æäº¤ï¼š

```bash
# åŠŸèƒ½
git commit -m "feat: æ·»åŠ  arXiv çˆ¬è™«æ”¯æŒ"

# é”™è¯¯ä¿®å¤
git commit -m "fix: è§£å†³å¤§å‹ PDF çš„ OCR è¶…æ—¶é—®é¢˜"

# æ–‡æ¡£
git commit -m "docs: æ›´æ–°æ–°ç«¯ç‚¹çš„ API å‚è€ƒ"

# æ€§èƒ½
git commit -m "perf: ä¼˜åŒ–é—®ç­”ç”Ÿæˆå™¨çš„æ‰¹å¤„ç†"

# é‡æ„
git commit -m "refactor: ç®€åŒ–é…ç½®ç®¡ç†å™¨å®ç°"

# æµ‹è¯•
git commit -m "test: æ·»åŠ æµæ°´çº¿é›†æˆæµ‹è¯•"

# æ‚é¡¹
git commit -m "chore: æ›´æ–°ä¾èµ–"
```

### 3. æ‹‰å–è¯·æ±‚æµç¨‹

1. **æ›´æ–°ä½ çš„ fork**
```bash
git fetch upstream
git checkout main
git merge upstream/main
```

2. **åˆ›å»ºåŠŸèƒ½åˆ†æ”¯**
```bash
git checkout -b feature/your-feature
```

3. **ä¿®æ”¹å¹¶æµ‹è¯•**
```bash
# è¿›è¡Œä¿®æ”¹
# è¿è¡Œæµ‹è¯•
pytest
# è¿è¡Œä»£ç æ£€æŸ¥
flake8 src/
black src/
```

4. **æäº¤å¹¶æ¨é€**
```bash
git add .
git commit -m "feat: ä½ çš„åŠŸèƒ½æè¿°"
git push origin feature/your-feature
```

5. **åˆ›å»ºæ‹‰å–è¯·æ±‚**
- å‰å¾€ GitHub åˆ›å»º PR
- å¡«å†™ PR æ¨¡æ¿
- å…³è”ç›¸å…³ issue
- è¯·æ±‚å®¡æŸ¥

### 4. ä»£ç å®¡æŸ¥æŒ‡å—

**å®¡æŸ¥è€…ï¼š**
- æ£€æŸ¥ä»£ç æ˜¯å¦éµå¾ªè§„èŒƒ
- éªŒè¯æ˜¯å¦åŒ…å«æµ‹è¯•
- ç¡®ä¿æ–‡æ¡£å·²æ›´æ–°
- å¦‚å¯èƒ½ï¼Œåœ¨æœ¬åœ°æµ‹è¯•
- æä¾›å»ºè®¾æ€§åé¦ˆ

**ä½œè€…ï¼š**
- å›åº”æ‰€æœ‰è¯„è®º
- è¿›è¡Œè¯·æ±‚çš„ä¿®æ”¹
- å¦‚èŒƒå›´å˜åŒ–ï¼Œæ›´æ–° PR æè¿°
- å¿…è¦æ—¶è¿›è¡Œå˜åŸº

## å‘å¸ƒæµç¨‹

### 1. ç‰ˆæœ¬å·è§„åˆ™

éµå¾ªè¯­ä¹‰åŒ–ç‰ˆæœ¬ï¼ˆä¸»ç‰ˆæœ¬.æ¬¡ç‰ˆæœ¬.ä¿®è®¢ç‰ˆæœ¬ï¼‰ï¼š
- ä¸»ç‰ˆæœ¬ï¼šé‡å¤§å˜æ›´
- æ¬¡ç‰ˆæœ¬ï¼šæ–°åŠŸèƒ½ï¼ˆå‘åå…¼å®¹ï¼‰
- ä¿®è®¢ç‰ˆæœ¬ï¼šé”™è¯¯ä¿®å¤

### 2. å‘å¸ƒæ¸…å•

```markdown
- [ ] æ‰€æœ‰æµ‹è¯•é€šè¿‡
- [ ] æ–‡æ¡£å·²æ›´æ–°
- [ ] CHANGELOG.md å·²æ›´æ–°
- [ ] setup.py ä¸­ç‰ˆæœ¬å·å·²æ›´æ–°
- [ ] å‘å¸ƒè¯´æ˜å·²å‡†å¤‡
- [ ] å·²åœ¨ git ä¸­æ‰“æ ‡ç­¾
- [ ] åŒ…å·²æ„å»ºå’Œæµ‹è¯•
```

### 3. å‘å¸ƒå‘½ä»¤

```bash
# æ›´æ–°ç‰ˆæœ¬
bump2version patch  # æˆ– minorã€major

# åˆ›å»ºå‘å¸ƒæ ‡ç­¾
git tag -a v1.2.3 -m "å‘å¸ƒç‰ˆæœ¬ 1.2.3"

# æ¨é€æ ‡ç­¾
git push origin v1.2.3

# æ„å»ºåŒ…
python setup.py sdist bdist_wheel

# ä¸Šä¼ åˆ° PyPIï¼ˆå¦‚é€‚ç”¨ï¼‰
twine upload dist/*
```

## æœ€ä½³å®è·µ

### 1. é”™è¯¯å¤„ç†

```python
class ProcessingError(Exception):
    """å¤„ç†é”™è¯¯çš„è‡ªå®šä¹‰å¼‚å¸¸"""
    pass

def robust_process(data):
    """å…·æœ‰å®Œå–„é”™è¯¯å¤„ç†çš„æ•°æ®å¤„ç†"""
    try:
        # éªŒè¯è¾“å…¥
        if not validate_data(data):
            raise ValueError("æ— æ•ˆçš„æ•°æ®æ ¼å¼")
        
        # å¤„ç†
        result = process_internal(data)
        
        # éªŒè¯è¾“å‡º
        if not validate_result(result):
            raise ProcessingError("å¤„ç†äº§ç”Ÿäº†æ— æ•ˆç»“æœ")
        
        return result
    
    except ValueError as e:
        logger.error(f"éªŒè¯é”™è¯¯: {e}")
        raise
    except ProcessingError as e:
        logger.error(f"å¤„ç†é”™è¯¯: {e}")
        # å°è¯•æ¢å¤æˆ–ä¼˜é›…é™çº§
        return process_fallback(data)
    except Exception as e:
        logger.critical(f"æ„å¤–é”™è¯¯: {e}", exc_info=True)
        raise
```

### 2. é…ç½®ç®¡ç†

```python
from dataclasses import dataclass
from typing import Optional

@dataclass
class ProcessorConfig:
    """å¤„ç†å™¨é…ç½®"""
    batch_size: int = 10
    timeout: int = 300
    retry_count: int = 3
    gpu_enabled: bool = False
    
    def validate(self) -> bool:
        """éªŒè¯é…ç½®"""
        if self.batch_size < 1:
            raise ValueError("æ‰¹å¤„ç†å¤§å°å¿…é¡»ä¸ºæ­£æ•°")
        if self.timeout < 0:
            raise ValueError("è¶…æ—¶æ—¶é—´å¿…é¡»éè´Ÿ")
        return True
```

### 3. èµ„æºç®¡ç†

```python
from contextlib import contextmanager

@contextmanager
def managed_resource(resource_path):
    """èµ„æºå¤„ç†çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    resource = None
    try:
        resource = acquire_resource(resource_path)
        yield resource
    finally:
        if resource:
            release_resource(resource)

# ä½¿ç”¨æ–¹æ³•
with managed_resource("/path/to/resource") as resource:
    process_with_resource(resource)
```

## å¼€å‘é—®é¢˜æ’æŸ¥

### å¸¸è§é—®é¢˜

1. **å¯¼å…¥é”™è¯¯**
```bash
# å°†é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ° PYTHONPATH
export PYTHONPATH="${PYTHONPATH}:$(pwd)"
```

2. **ä¾èµ–å†²çª**
```bash
# ä½¿ç”¨ pip-tools ç®¡ç†ä¾èµ–
pip install pip-tools
pip-compile requirements.in
pip-sync
```

3. **æµ‹è¯•å¤±è´¥**
```bash
# æ¸…é™¤æµ‹è¯•ç¼“å­˜
pytest --cache-clear

# è¿è¡Œæ›´è¯¦ç»†çš„è¾“å‡º
pytest -vvs
```

4. **å¼€å‘æ—¶çš„å†…å­˜é—®é¢˜**
```python
# ä½¿ç”¨å†…å­˜åˆ†æ
import tracemalloc
tracemalloc.start()

# ä½ çš„ä»£ç 
snapshot = tracemalloc.take_snapshot()
top_stats = snapshot.statistics('lineno')
for stat in top_stats[:10]:
    print(stat)
```

## èµ„æºé“¾æ¥

### æ–‡æ¡£èµ„æ–™
- [Python é£æ ¼æŒ‡å— (PEP 8)](https://pep8.org/)
- [Google Python é£æ ¼æŒ‡å—](https://google.github.io/styleguide/pyguide.html)
- [pytest æ–‡æ¡£](https://docs.pytest.org/)

### å·¥å…·
- [Black - ä»£ç æ ¼å¼åŒ–](https://black.readthedocs.io/)
- [Flake8 - é£æ ¼æ£€æŸ¥](https://flake8.pycqa.org/)
- [mypy - ç±»å‹æ£€æŸ¥](http://mypy-lang.org/)
- [pre-commit - Git é’©å­](https://pre-commit.com/)

### å­¦ä¹ èµ„æº
- [Real Python æ•™ç¨‹](https://realpython.com/)
- [Python æµ‹è¯•å…¥é—¨](https://realpython.com/python-testing/)
- [Effective Python](https://effectivepython.com/)